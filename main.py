import streamlit as st
import requests
from bs4 import BeautifulSoup
import urllib.parse # Importa para analisar URLs

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="Busca de Produtos Nagumo", page_icon="üõí")

# CSS para remover o espa√ßo superior
st.markdown("""
    <style>
        .block-container {
            padding-top: 0rem;
        }
    </style>
""", unsafe_allow_html=True)

# T√≠tulo com fonte menor
st.markdown("<h5>üõíPre√ßos Nagumo</h5>", unsafe_allow_html=True)

busca = st.text_input("Digite o nome do produto:")

def buscar_produto_nagumo(palavra_chave):
    palavra_chave_url = palavra_chave.strip().lower().replace(" ", "+")
    url = f"https://www.nagumo.com.br/nagumo/74b2f698-cffc-4a38-b8ce-0407f8d98de3/busca/{palavra_chave_url}" 
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        r = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        search_words = set(palavra_chave.lower().split())
        
        # Encontra todos os poss√≠veis blocos de produtos na p√°gina
        all_product_blocks = soup.find_all('div', class_='sc-c5cd0085-0 fWmXTW')

        for product_block in all_product_blocks:
            nome_text = "Nome n√£o encontrado"
            preco_text = "Pre√ßo n√£o encontrado"
            descricao_text = "Descri√ß√£o n√£o encontrada"
            img_url = None
            product_identified = False

            # Inicializa img_tag aqui para garantir que esteja sempre definida
            img_tag = product_block.find('img') 

            # Primeiro, tenta encontrar o nome no span (onde o nome do produto geralmente aparece)
            nome_tag = product_block.find('span', class_='sc-fLlhyt hJreDe sc-14455254-0 sc-c5cd0085-4 ezNOEq clsIKA')
            if nome_tag:
                span_name_text = nome_tag.text.strip()
                span_name_words = set(span_name_text.lower().split())
                if search_words.issubset(span_name_words):
                    nome_text = span_name_text
                    product_identified = True
            
            # Se n√£o encontrar no span, tenta verificar o atributo 'alt' da imagem (muitas vezes cont√©m o nome)
            # Usa a img_tag j√° encontrada
            if not product_identified:
                if img_tag and 'alt' in img_tag.attrs:
                    img_alt_text = img_tag['alt'].strip()
                    img_alt_words = set(img_alt_text.lower().split())
                    if search_words.issubset(img_alt_words):
                        nome_text = img_alt_text
                        product_identified = True

            # Se o produto foi identificado (seja pelo nome do span ou pelo alt da imagem)
            if product_identified:
                # Extrai o pre√ßo e a descri√ß√£o
                preco_tag = product_block.find('span', class_='sc-fLlhyt fKrYQk sc-14455254-0 sc-c5cd0085-9 ezNOEq dDNfcV')
                preco_text = preco_tag.text.strip() if preco_tag else "Pre√ßo n√£o encontrado"
                
                descricao_tag = product_block.find('span', class_='sc-fLlhyt dPLwZv sc-14455254-0 sc-c5cd0085-10 ezNOEq krnAMj')
                descricao_text = descricao_tag.text.strip() if descricao_tag else "Descri√ß√£o n√£o encontrada"
                
                # --- L√≥gica para encontrar a URL da imagem real ---
                if img_tag:
                    current_src = img_tag.get('src')
                    
                    # Se o 'src' n√£o √© um placeholder (data:image/gif), usa ele
                    if current_src and not current_src.startswith('data:image/gif'):
                        img_url = current_src
                    else:
                        # Se o 'src' √© um placeholder, tenta pegar do 'srcset'
                        srcset = img_tag.get('srcset')
                        if srcset:
                            # Pega a primeira URL do srcset (ex: "url 1x")
                            first_src_entry = srcset.split(',')[0].strip()
                            potential_url = first_src_entry.split(' ')[0] # Extrai apenas a parte da URL
                            
                            # Verifica se √© uma URL de proxy do Next.js (ex: /_next/image?url=...)
                            if "/_next/image" in potential_url:
                                try:
                                    # Analisa a URL do proxy para obter o par√¢metro 'url' real
                                    parsed_proxy_url = urllib.parse.urlparse(potential_url)
                                    query_params = urllib.parse.parse_qs(parsed_proxy_url.query)
                                    
                                    if 'url' in query_params:
                                        # O par√¢metro 'url' cont√©m o caminho da imagem real, possivelmente codificado
                                        actual_image_path = query_params['url'][0]
                                        # Garante que est√° totalmente decodificado (ex: %2F para /)
                                        actual_image_path_decoded = urllib.parse.unquote(actual_image_path)
                                        
                                        # Se o caminho real da imagem come√ßar com '/image/upload', √© prov√°vel que seja do ifood
                                        if actual_image_path_decoded.startswith('/image/upload'):
                                            img_url = f"https://static-images.ifood.com.br{actual_image_path_decoded}"
                                        else:
                                            # Caso contr√°rio, assume que √© um caminho relativo ao dom√≠nio do Nagumo
                                            img_url = f"https://www.nagumo.com.br{actual_image_path_decoded}"
                                except Exception as e:
                                    # Em caso de erro na an√°lise da URL do proxy, apenas registra e n√£o retorna imagem
                                    print(f"Erro ao analisar URL de proxy do Next.js: {e}")
                                    img_url = None 
                            elif potential_url.startswith('/'):
                                # Se for uma URL relativa padr√£o, prefixa com o dom√≠nio do Nagumo
                                img_url = f"https://www.nagumo.com.br{potential_url}"
                            else:
                                img_url = potential_url # Assume que j√° √© uma URL absoluta
                
                return nome_text, preco_text, descricao_text, img_url
        
        # Se nenhum produto correspondente for encontrado
        return "Nome n√£o encontrado", "Pre√ßo n√£o encontrado", "Descri√ß√£o n√£o encontrada", None

    except requests.exceptions.RequestException as e:
        st.error(f"Erro de conex√£o ao buscar produtos: {e}")
        return "Erro na busca", "", "", None
    except Exception as e:
        st.error(f"Ocorreu um erro inesperado durante a busca: {e}")
        return "Erro na busca", "", "", None

# Exibi√ß√£o do Resultado
if busca:
    nome, preco, descricao, imagem_url = buscar_produto_nagumo(busca)
    
    st.write(f"**Produto:** {nome}")
    st.write(f"**Pre√ßo:** {preco}")
    st.write(f"**Descri√ß√£o:** {descricao}")
    
    # S√≥ tenta exibir a imagem se a URL foi realmente encontrada
    if imagem_url:
        st.image(imagem_url, caption=nome, width=200)
    elif nome != "Nome n√£o encontrado" and nome != "Erro na busca":
        # Mensagem opcional se o produto foi encontrado, mas a imagem n√£o
        st.write("Imagem n√£o encontrada para este produto.")
    
    if nome == "Nome n√£o encontrado":
        st.write("Produto n√£o encontrado.")
